{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1412421-a706-4445-a530-7ab731e8b4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 69.7ms\n",
      "Speed: 3.8ms preprocess, 69.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 66.8ms\n",
      "Speed: 2.4ms preprocess, 66.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\n",
      "0: 384x640 1 face, 51.6ms\n",
      "Speed: 1.6ms preprocess, 51.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.7ms\n",
      "Speed: 1.6ms preprocess, 52.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 1.7ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\n",
      "0: 384x640 1 face, 62.4ms\n",
      "Speed: 3.3ms preprocess, 62.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\n",
      "0: 384x640 1 face, 50.0ms\n",
      "Speed: 2.2ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\n",
      "0: 384x640 1 face, 60.4ms\n",
      "Speed: 2.4ms preprocess, 60.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\n",
      "0: 384x640 1 face, 48.9ms\n",
      "Speed: 2.4ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.8ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.3ms\n",
      "Speed: 2.5ms preprocess, 55.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\n",
      "0: 384x640 1 face, 48.3ms\n",
      "Speed: 1.8ms preprocess, 48.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\n",
      "0: 384x640 1 face, 58.6ms\n",
      "Speed: 2.4ms preprocess, 58.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.4ms\n",
      "Speed: 2.5ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.8ms\n",
      "Speed: 2.1ms preprocess, 51.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.5ms\n",
      "Speed: 2.1ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\n",
      "0: 384x640 1 face, 60.9ms\n",
      "Speed: 2.4ms preprocess, 60.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.2ms preprocess, 46.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\n",
      "0: 384x640 1 face, 49.1ms\n",
      "Speed: 2.6ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.3ms\n",
      "Speed: 2.6ms preprocess, 55.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\n",
      "0: 384x640 1 face, 47.7ms\n",
      "Speed: 2.3ms preprocess, 47.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.4ms\n",
      "Speed: 2.4ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\n",
      "0: 384x640 1 face, 56.6ms\n",
      "Speed: 2.5ms preprocess, 56.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\n",
      "0: 384x640 1 face, 61.2ms\n",
      "Speed: 2.7ms preprocess, 61.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.5ms\n",
      "Speed: 2.1ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\n",
      "0: 384x640 1 face, 60.8ms\n",
      "Speed: 2.7ms preprocess, 60.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\n",
      "0: 384x640 1 face, 60.6ms\n",
      "Speed: 2.3ms preprocess, 60.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\n",
      "0: 384x640 1 face, 68.0ms\n",
      "Speed: 2.8ms preprocess, 68.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\n",
      "0: 384x640 1 face, 60.9ms\n",
      "Speed: 2.7ms preprocess, 60.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\n",
      "0: 384x640 1 face, 73.4ms\n",
      "Speed: 3.4ms preprocess, 73.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\n",
      "0: 384x640 1 face, 62.4ms\n",
      "Speed: 2.2ms preprocess, 62.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\n",
      "0: 384x640 1 face, 72.2ms\n",
      "Speed: 3.0ms preprocess, 72.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\n",
      "0: 384x640 1 face, 43.3ms\n",
      "Speed: 1.9ms preprocess, 43.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\n",
      "0: 384x640 1 face, 63.8ms\n",
      "Speed: 3.3ms preprocess, 63.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "\n",
      "0: 384x640 1 face, 50.7ms\n",
      "Speed: 2.9ms preprocess, 50.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\n",
      "0: 384x640 1 face, 57.7ms\n",
      "Speed: 2.5ms preprocess, 57.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\n",
      "0: 384x640 1 face, 57.9ms\n",
      "Speed: 2.6ms preprocess, 57.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\n",
      "0: 384x640 1 face, 54.5ms\n",
      "Speed: 2.7ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\n",
      "0: 384x640 1 face, 56.0ms\n",
      "Speed: 2.7ms preprocess, 56.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.0ms\n",
      "Speed: 2.5ms preprocess, 55.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.1ms\n",
      "Speed: 2.6ms preprocess, 55.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\n",
      "0: 384x640 1 face, 73.3ms\n",
      "Speed: 2.4ms preprocess, 73.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\n",
      "0: 384x640 1 face, 54.3ms\n",
      "Speed: 2.4ms preprocess, 54.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\n",
      "0: 384x640 1 face, 54.4ms\n",
      "Speed: 2.5ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\n",
      "0: 384x640 1 face, 58.0ms\n",
      "Speed: 2.5ms preprocess, 58.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\n",
      "0: 384x640 1 face, 50.6ms\n",
      "Speed: 2.1ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\n",
      "0: 384x640 1 face, 60.1ms\n",
      "Speed: 2.4ms preprocess, 60.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "\n",
      "0: 384x640 1 face, 56.0ms\n",
      "Speed: 2.1ms preprocess, 56.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\n",
      "0: 384x640 1 face, 49.6ms\n",
      "Speed: 2.2ms preprocess, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.5ms\n",
      "Speed: 2.5ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.9ms\n",
      "Speed: 2.5ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\n",
      "0: 384x640 1 face, 57.0ms\n",
      "Speed: 2.4ms preprocess, 57.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\n",
      "0: 384x640 1 face, 66.4ms\n",
      "Speed: 2.8ms preprocess, 66.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "\n",
      "0: 384x640 1 face, 49.8ms\n",
      "Speed: 2.1ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\n",
      "0: 384x640 1 face, 59.0ms\n",
      "Speed: 2.7ms preprocess, 59.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.5ms\n",
      "Speed: 2.2ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\n",
      "0: 384x640 1 face, 56.5ms\n",
      "Speed: 2.5ms preprocess, 56.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.1ms\n",
      "Speed: 2.1ms preprocess, 55.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\n",
      "0: 384x640 1 face, 48.5ms\n",
      "Speed: 2.2ms preprocess, 48.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\n",
      "0: 384x640 1 face, 56.9ms\n",
      "Speed: 2.5ms preprocess, 56.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.0ms\n",
      "Speed: 1.8ms preprocess, 52.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\n",
      "0: 384x640 1 face, 63.1ms\n",
      "Speed: 2.7ms preprocess, 63.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\n",
      "0: 384x640 1 face, 65.6ms\n",
      "Speed: 2.2ms preprocess, 65.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\n",
      "0: 384x640 1 face, 48.3ms\n",
      "Speed: 2.2ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\n",
      "0: 384x640 1 face, 56.9ms\n",
      "Speed: 2.7ms preprocess, 56.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\n",
      "0: 384x640 1 face, 57.9ms\n",
      "Speed: 2.6ms preprocess, 57.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\n",
      "0: 384x640 1 face, 58.8ms\n",
      "Speed: 2.6ms preprocess, 58.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "\n",
      "0: 384x640 1 face, 53.5ms\n",
      "Speed: 2.2ms preprocess, 53.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\n",
      "0: 384x640 1 face, 54.3ms\n",
      "Speed: 2.9ms preprocess, 54.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.5ms\n",
      "Speed: 2.1ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\n",
      "0: 384x640 1 face, 59.6ms\n",
      "Speed: 2.8ms preprocess, 59.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "\n",
      "0: 384x640 1 face, 43.2ms\n",
      "Speed: 2.0ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\n",
      "0: 384x640 1 face, 62.9ms\n",
      "Speed: 2.4ms preprocess, 62.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\n",
      "0: 384x640 1 face, 65.4ms\n",
      "Speed: 2.9ms preprocess, 65.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 1.8ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\n",
      "0: 384x640 1 face, 62.1ms\n",
      "Speed: 2.5ms preprocess, 62.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\n",
      "0: 384x640 1 face, 54.9ms\n",
      "Speed: 2.1ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\n",
      "0: 384x640 1 face, 77.6ms\n",
      "Speed: 2.2ms preprocess, 77.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.5ms\n",
      "Speed: 2.2ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\n",
      "0: 384x640 1 face, 54.0ms\n",
      "Speed: 2.6ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\n",
      "0: 384x640 1 face, 59.2ms\n",
      "Speed: 2.8ms preprocess, 59.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\n",
      "0: 384x640 1 face, 71.1ms\n",
      "Speed: 2.6ms preprocess, 71.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\n",
      "0: 384x640 1 face, 54.0ms\n",
      "Speed: 2.4ms preprocess, 54.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\n",
      "0: 384x640 1 face, 83.7ms\n",
      "Speed: 2.6ms preprocess, 83.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "\n",
      "0: 384x640 1 face, 73.2ms\n",
      "Speed: 2.9ms preprocess, 73.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\n",
      "0: 384x640 1 face, 68.2ms\n",
      "Speed: 2.9ms preprocess, 68.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\n",
      "0: 384x640 1 face, 50.5ms\n",
      "Speed: 2.1ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.4ms\n",
      "Speed: 2.4ms preprocess, 55.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.6ms\n",
      "Speed: 2.3ms preprocess, 52.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\n",
      "0: 384x640 1 face, 83.4ms\n",
      "Speed: 3.2ms preprocess, 83.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "\n",
      "0: 384x640 1 face, 64.1ms\n",
      "Speed: 2.4ms preprocess, 64.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\n",
      "0: 384x640 1 face, 60.0ms\n",
      "Speed: 2.2ms preprocess, 60.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\n",
      "0: 384x640 1 face, 55.7ms\n",
      "Speed: 3.0ms preprocess, 55.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\n",
      "0: 384x640 1 face, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
      "\n",
      "0: 384x640 1 face, 58.2ms\n",
      "Speed: 2.1ms preprocess, 58.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\n",
      "0: 384x640 1 face, 78.7ms\n",
      "Speed: 2.7ms preprocess, 78.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\n",
      "0: 384x640 1 face, 72.6ms\n",
      "Speed: 2.3ms preprocess, 72.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.4ms\n",
      "Speed: 2.1ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\n",
      "0: 384x640 1 face, 71.2ms\n",
      "Speed: 3.0ms preprocess, 71.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "\n",
      "0: 384x640 1 face, 61.0ms\n",
      "Speed: 7.9ms preprocess, 61.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\n",
      "0: 384x640 1 face, 59.2ms\n",
      "Speed: 2.6ms preprocess, 59.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\n",
      "0: 384x640 1 face, 66.1ms\n",
      "Speed: 2.9ms preprocess, 66.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\n",
      "0: 384x640 1 face, 53.8ms\n",
      "Speed: 2.0ms preprocess, 53.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\n",
      "0: 384x640 1 face, 65.1ms\n",
      "Speed: 2.6ms preprocess, 65.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\n",
      "0: 384x640 1 face, 59.6ms\n",
      "Speed: 7.8ms preprocess, 59.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\n",
      "0: 384x640 1 face, 51.2ms\n",
      "Speed: 2.3ms preprocess, 51.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\n",
      "0: 384x640 1 face, 63.0ms\n",
      "Speed: 2.9ms preprocess, 63.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\n",
      "0: 384x640 1 face, 53.6ms\n",
      "Speed: 2.0ms preprocess, 53.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\n",
      "0: 384x640 1 face, 65.1ms\n",
      "Speed: 3.4ms preprocess, 65.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\n",
      "0: 384x640 1 face, 77.0ms\n",
      "Speed: 2.3ms preprocess, 77.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.4ms\n",
      "Speed: 2.7ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\n",
      "0: 384x640 1 face, 58.8ms\n",
      "Speed: 2.2ms preprocess, 58.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "\n",
      "0: 384x640 1 face, 52.7ms\n",
      "Speed: 2.0ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\n",
      "0: 384x640 1 face, 58.7ms\n",
      "Speed: 2.6ms preprocess, 58.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\n",
      "0: 384x640 1 face, 74.7ms\n",
      "Speed: 2.5ms preprocess, 74.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "\n",
      "0: 384x640 1 face, 63.9ms\n",
      "Speed: 2.9ms preprocess, 63.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\n",
      "0: 384x640 1 face, 59.6ms\n",
      "Speed: 2.5ms preprocess, 59.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import imutils\n",
    "\n",
    "yolo_model = YOLO(\"face_yolov8n.pt\")  \n",
    "emotion_model_path = 'Model_Final_emotion_recgontion.h5'\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "\n",
    "emotion_label = ['angry', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "cv2.namedWindow('app face recogniton by Eng ahmed')\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    canvas = np.zeros((300, 400, 3), dtype=\"uint8\")\n",
    "    frame_clone = frame.copy()\n",
    "\n",
    "    results = yolo_model(frame)\n",
    "    faces = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True, key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))\n",
    "        x1, y1, x2, y2 = faces[0].astype(int)\n",
    "\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        roi = cv2.resize(roi, (224, 224))\n",
    "        roi = roi.astype(\"float32\") / 255.0\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = emotion_label[preds.argmax()]\n",
    "\n",
    "        for (i, (emotion, prob)) in enumerate(zip(emotion_label, preds)):\n",
    "            text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "            w = int(prob * 300)\n",
    "            cv2.rectangle(canvas, (7, (i * 35) + 5), (w, (i * 35) + 35), (239,191,4), -1)\n",
    "            cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (11,218,817), 2)\n",
    "\n",
    "        cv2.putText(frame_clone, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame_clone, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('app face recogniton by Eng ahmed', frame_clone)\n",
    "    cv2.imshow(\"Prob\", canvas)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84f012-2d45-4a89-a789-0266058daa86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
